<<<<<<< Updated upstream
x <- seq(0, 1. 0.01)
x <- seq(0, 1, 0.01)
plot(x, sqrt(x))
x <- seq(0.01, 0.99, 0.01)
y <- log(x / (1 - x))
plot(x, sqrt(y))
y
plot(x, y)
plot(y, x)
plot(y, sqrt(x))
plot(y, sqrt(x), ylim = c(0, 1), bty = "l")
plot(y, x, ylim = c(0, 1), bty = "l")
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/sim_data_to_R.R")
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/sim_data_to_R.R")
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/sim_data_to_R.R")
DF
df
load("Data/glance_dec_data.R")
res <- active_learning (df, sampling_method = c("uniform"),
target = c("none"),
reduce_simulations_by_logic = TRUE, # TRUE or FALSE
num_cases_per_iteration = 1,
niter = 100,
nboot = 100)
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
res <- active_learning (df, sampling_method = c("uniform"),
target = c("none"),
reduce_simulations_by_logic = TRUE, # TRUE or FALSE
num_cases_per_iteration = 1,
niter = 100,
nboot = 100)
res
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
View(res)
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
sampling_method = c("uniform",
"propto eoff_acc_prob",
"propto eoff_acc_prob * eoff * maximpact0",
"propto eoff_acc_prob * abs(acc) * maximpact0",
"propto eoff_acc_prob * eoff * abs(acc) * maximpact0",
"optimised"),
target = c("none",
"baseline impact speed distribution",
"impact speed reduction",
"crash avoidance",
"injury risk reduction",
"injury risk reduction, stratified")
sampling_method = c("uniform",
"propto eoff_acc_prob",
"propto eoff_acc_prob * eoff * maximpact0",
"propto eoff_acc_prob * abs(acc) * maximpact0",
"propto eoff_acc_prob * eoff * abs(acc) * maximpact0",
"optimised")
target = c("none",
"baseline impact speed distribution",
"impact speed reduction",
"crash avoidance",
"injury risk reduction",
"injury risk reduction, stratified")
sampling_method
sampling_method[1]
sampling_method[2]
target[1]
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/sim_data_to_R.R")
library("tidyverse")
library("ggplot2")
g <- ggplot(res, aes(x = iter, y = absolute_impact_speed_reduction_se))
res
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/sim_data_to_R.R")
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/sim_data_to_R.R")
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/sim_data_to_R.R")
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/sim_data_to_R.R")
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/sim_data_to_R.R")
source('Rscripts/load_packages.R')
source('Rscript/load_packages.R')
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/sim_data_to_R.R")
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/sim_data_to_R.R")
sampling_method = c("uniform",
"propto eoff_acc_prob",
"propto eoff_acc_prob * eoff * maximpact0",
"propto eoff_acc_prob * abs(acc) * maximpact0",
"propto eoff_acc_prob * eoff * abs(acc) * maximpact0",
"optimised")
target = c("none",
"baseline impact speed distribution",
"impact speed reduction",
"crash avoidance",
"injury risk reduction",
"injury risk reduction, stratified")
res <- active_learning (df, sampling_method = c("uniform"),
target = c("none"),
reduce_simulations_by_logic = TRUE, # TRUE or FALSE
num_cases_per_iteration = 1,
niter = 100,
nboot = 100)
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
g <- ggplot(res, aes(x = iter, y = absolute_impact_speed_reduction_se))
res
res
ggplot(res, aes(x = iter, y = absolute_impact_speed_reduction_se))
g <- ggplot(res$results, aes(x = iter, y = absolute_impact_speed_reduction_se))
g
g <- ggplot(res$results, aes(x = iter, y = absolute_impact_speed_reduction_se)) +
geom_point()
g
g <- ggplot(res$results, aes(x = iter, y = sqrt(absolute_impact_speed_reduction_sqerr))) +
geom_point()
g
g <- ggplot(res$results, aes(x = iter, y = sqrt(absolute_impact_speed_reduction_sqerr))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)
g
g <- ggplot(res$results, aes(x = iter, y = sqrt(absolute_impact_speed_reduction_sqerr))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = "Impact_speed_reduction_sd")
g
g <- ggplot(res$results, aes(x = iter, y = sqrt(absolute_impact_speed_reduction_sqerr))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = "Impact speed reductio sd")
g
g <- ggplot(res$results, aes(x = iter, y = sqrt(absolute_impact_speed_reduction_sqerr))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = "Impact speed reductio sd")+
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 2, size = 15))
g
g <- ggplot(res$results, aes(x = iter, y = sqrt(absolute_impact_speed_reduction_sqerr))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = "Impact speed reductio sd")+
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 2, size = 15),
axis.text = element_text(size = 12))
g <- ggplot(res$results, aes(x = iter, y = sqrt(absolute_impact_speed_reduction_sqerr))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = "Impact speed reductio sd")+
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 2, size = 15),
axis.text = element_text(size = 15))
g <- ggplot(res$results, aes(x = iter, y = sqrt(absolute_impact_speed_reduction_sqerr))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = "Impact speed reductio sd")+
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 2, size = 15),
axis.text = element_text(color = "dodgerblue", size = 12),
axis.text.x = element_text(face = "italic"))
g
g <- ggplot(res$results, aes(x = iter, y = sqrt(absolute_impact_speed_reduction_sqerr))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = "Impact speed reductio sd")+
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 2, size = 15),
axis.text = element_text(size = 12))
g
g <- ggplot(res$results, aes(x = iter, y = sqrt(absolute_impact_speed_reduction_sqerr))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = "Impact speed reductio sd")+
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 2, size = 15),
axis.text = element_text(size = 12))+
ggtitle("Impact speed reduction sd for sampling method")
g
view(res$results)
target[2:end]
target[2:end]
target[2:5]
res$results
res$results$mean_impact_speed0_sqerr
res$results$absolute_impact_speed_reduction_sqerr
str('t')
t
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
c("Impact speed baseline sd for sampling method " + i)
"Impact speed baseline sd for sampling method "
i
type(i)
class(i)
class("Impact speed baseline sd for sampling method ")
paste("Impact speed baseline sd for sampling method " + i)
paste("Impact speed baseline sd for sampling method " ,i)
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
ggsave(sprintf("Output/fig%d.png", fcount), g1, dpi = 1000, width = 270, height = 270, unit = "mm")
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
out_param
res$results$out_param
res$results[out_param]
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
g3 <- ggplot(res$results, aes(x = iter, y = sqrt(out_param_val))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = out_param)+
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 2, size = 15),
axis.text = element_text(size = 12))+
ggtitle(paste(out_param, "sd for sampling method-" ,i))
g3
g2
g2 <- ggplot(res$results, aes(x = iter, y = sqrt(results[out_param]))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = out_param)+
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 2, size = 15),
axis.text = element_text(size = 12))+
ggtitle(paste(out_param, "sd for sampling method:" ,i))
g2
g2 <- ggplot(res$results, aes(x = iter, y = sqrt(res$results[out_param]))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = out_param)+
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 2, size = 15),
axis.text = element_text(size = 12))+
ggtitle(paste(out_param, "sd for sampling method:" ,i))
g2
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
load("Data/glance_dec_data.R")
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
sampling_method
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
target[2:5]
total_iter = 10
total_nboot = 10
for ( j in c(TRUE,FALSE)){
for (i in sampling_method[1:5]){
res <- active_learning (df, sampling_method = i,
target = "none",
reduce_simulations_by_logic = j, # TRUE or FALSE
num_cases_per_iteration = 1,
niter = total_iter,
nboot = total_nboot)
g3 <- ggplot(res$results, aes(x = iter, y = sqrt(mean_impact_speed0_sqerr))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = "Baseline impact speed sd")+
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 2, size = 15),
axis.text = element_text(size = 12))+
ggtitle(paste("Impact speed baseline sd for" ,i,"and reduced logic is",j))
ggsave(sprintf("Output/fig%d.png", fcount), g3, dpi = 1000, width = 270, height = 270, unit = "mm")
fcount <- fcount + 1
ggsave(sprintf("Output/fig%d.png", fcount), g2, dpi = 1000, width = 270, height = 270, unit = "mm")
fcount <- fcount + 1
}
}
for ( j in c(TRUE,FALSE)){
for (i in sampling_method[1:5]){
res <- active_learning (df, sampling_method = i,
target = "none",
reduce_simulations_by_logic = j, # TRUE or FALSE
num_cases_per_iteration = 1,
niter = total_iter,
nboot = total_nboot)
g3 <- ggplot(res$results, aes(x = iter, y = sqrt(mean_impact_speed0_sqerr))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = "Baseline impact speed sd")+
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 2, size = 15),
axis.text = element_text(size = 12))+
ggtitle(paste("Impact speed baseline sd for" ,i,"and reduced logic is",j))
ggsave(sprintf("Output/fig%d.png", fcount), g3, dpi = 1000, width = 270, height = 270, unit = "mm")
fcount <- fcount + 1
}
}
fcount = 1
for ( j in c(TRUE,FALSE)){
for (i in sampling_method[1:5]){
res <- active_learning (df, sampling_method = i,
target = "none",
reduce_simulations_by_logic = j, # TRUE or FALSE
num_cases_per_iteration = 1,
niter = total_iter,
nboot = total_nboot)
g3 <- ggplot(res$results, aes(x = iter, y = sqrt(mean_impact_speed0_sqerr))) +
geom_point(color = "firebrick", shape = "diamond", size = 2)+
labs(x = "Iteration", y = "Baseline impact speed sd")+
theme(axis.title.x = element_text(vjust = 0, size = 15),
axis.title.y = element_text(vjust = 2, size = 15),
axis.text = element_text(size = 12))+
ggtitle(paste("Impact speed baseline sd for" ,i,"and reduced logic is",j))
ggsave(sprintf("Output/fig%d.png", fcount), g3, dpi = 1000, width = 270, height = 270, unit = "mm")
fcount <- fcount + 1
}
}
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
j
for ( j in c(TRUE,FALSE)){
print(j)}
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
out
out$results
list(res,out$results)
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
res
res
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
out
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
out$results
out$results
t = do.call("rbind", out$results)
t
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
res_list
length(res_list)
out$results
out$results$target[2]
t.a = 1
t
pp.a = 1
pp
pp.a
pp.b = 2
pp
res = do.call(rbind, res_list)
res
out$results
view(res)
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
Sim_n
index = seq(p,total_iter*Sim_n,Sim_n)
seq(p,total_iter*Sim_n,Sim_n)
total_iter = 10
Sim_n = 5
seq(p,total_iter*Sim_n,Sim_n)
seq(p,total_iter*Sim_n,total_iter)
total_iter = 2
seq(p,total_iter*Sim_n,total_iter)
index = seq(p,total_iter*Sim_n,total_iter)
res[index]
view(res[index])
view(res)
res$mean_impact_speed0_sqerr
res$mean_impact_speed0_sqerr[index]
aver$mean_impact_speed0_sqerr = 1
aver = data.frame()
aver$mean_impact_speed0_sqerr = 1
aver = data.frame(nrow = iter)
aver = data.frame(nrow = total_iter)
aver$mean_impact_speed0_sqerr = 1
aver
aver = data.frame(nrow = total_iter)
biggest = data.frame(nrow = total_iter)
smallest = data.frame(nrow = total_iter)
mean(res$mean_impact_speed0_sqerr[index])
aver$mean_impact_speed0_sqerr[i] = mean(res$mean_impact_speed0_sqerr[index])
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
res$mean_impact_speed0_sqerr[index]
mean(res$mean_impact_speed0_sqerr[index])
aver$mean_impact_speed0_sqerr
aver$mean_impact_speed0_sqerr[i] = mean(res$mean_impact_speed0_sqerr[index])
i
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index])
p
p = 1
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index])
p = 2
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index])
aver$mean_impact_speed0_sqerr
aver$mean_impact_speed0_sqerr[p]
mean(res$mean_impact_speed0_sqerr[index])
index = seq(p,total_iter*Sim_n,total_iter)
mean(res$mean_impact_speed0_sqerr[index])
p = 2
index = seq(p,total_iter*Sim_n,total_iter)
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index])
aver$mean_impact_speed0_sqerr
aver = data.frame(nrow = total_iter,ncol = 4)
biggest = data.frame(nrow = total_iter)
smallest = data.frame(nrow = total_iter)
for(p in 1:total_iter){
index = seq(p,total_iter*Sim_n,total_iter)
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index])
}
mean(res$mean_impact_speed0_sqerr[index])
p = 1
index = seq(p,total_iter*Sim_n,total_iter)
mean(res$mean_impact_speed0_sqerr[index])
view(res)
index
index = matrix(nrow = total_iter)
for(p in 1:total_iter){
index[,p] = seq(p,total_iter*Sim_n,total_iter)
}
index = matrix(ncol = total_iter)
for(p in 1:total_iter){
index[,p] = seq(p,total_iter*Sim_n,total_iter)
}
index = matrix(nrow = Sim_n,ncol = total_iter)
for(p in 1:total_iter){
index[,p] = seq(p,total_iter*Sim_n,total_iter)
}
index
index = matrix(nrow = total_iter,ncol = Sim_n)
for(p in 1:total_iter){
index[,p] = seq(p,total_iter*Sim_n,total_iter)
}
index = matrix(nrow = total_iter,ncol = Sim_n)
for(p in 1:total_iter){
index[p,] = seq(p,total_iter*Sim_n,total_iter)
}
index
mean(res$mean_impact_speed0_sqerr[index[p,]])
mean(res$mean_impact_speed0_sqerr[index[,]])
mean(res$mean_impact_speed0_sqerr[index[1,]])
mean(res$mean_impact_speed0_sqerr[index[2,]])
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index[p,]])
colnamesforres = c("mean_impact_speed0_sqerr")
colnames(aver) = colnamesforres
aver
for(p in 1:total_iter){
index[p,] = seq(p,total_iter*Sim_n,total_iter)
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index[p,]])
}
aver = na
aver = NA
for(p in 1:total_iter){
index[p,] = seq(p,total_iter*Sim_n,total_iter)
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index[p,]])
}
colnamesforres = c("mean_impact_speed0_sqerr")
aver = data.frame(nrow = total_iter,ncol = 4)
biggest = data.frame(nrow = total_iter)
smallest = data.frame(nrow = total_iter)
colnames(aver) = colnamesforres
index = matrix(nrow = total_iter,ncol = Sim_n)
for(p in 1:total_iter){
index[p,] = seq(p,total_iter*Sim_n,total_iter)
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index[p,]])
}
AVER
aver
colnamesforres = c("mean_impact_speed0_sqerr")
aver = data.frame(nrow = total_iter,ncol = 4)
aver
aver = data.frame(data= NA)
aver
for(p in 1:total_iter){
index[p,] = seq(p,total_iter*Sim_n,total_iter)
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index[p,]])
}
aver = as.data.frame(matrix(nrowtotal_iter,ncol=5))
aver = as.data.frame(matrix(nrow=total_iter,ncol=5))
index = matrix(nrow = total_iter,ncol = Sim_n)
for(p in 1:total_iter){
index[p,] = seq(p,total_iter*Sim_n,total_iter)
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index[p,]])
}
aver
aver = as.data.frame(matrix(nrow=total_iter,ncol=0))
aver
for(p in 1:total_iter){
index[p,] = seq(p,total_iter*Sim_n,total_iter)
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index[p,]])
}
aver
for(p in 1:total_iter){
index[p,] = seq(p,total_iter*Sim_n,total_iter)
aver$iter[p] = mean(res$mean_impact_speed0_sqerr[index[p,]])
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index[p,]])
}
aver
for(p in 1:total_iter){
index[p,] = seq(p,total_iter*Sim_n,total_iter)
aver$iter[p] = mean(res$iter[index[p,]])
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index[p,]])
}
aver
res$iter
for(p in 1:total_iter){
index[p,] = seq(p,total_iter*Sim_n,total_iter)
aver$iter[p] = mean(res$iter[p])
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index[p,]])
}
aver
for(p in 1:total_iter){
index[p,] = seq(p,total_iter*Sim_n,total_iter)
aver$iter[p] = mean(res$iter[p])
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index[p,]])
aver$absolute_impact_speed_reduction_sqerr[p] = mean(res$absolute_impact_speed_reduction_sqerr[index[p,]])
aver$proportion_crashes_avoided_sqerr[p] = mean(res$proportion_crashes_avoided_sqerr[index[p,]])
aver$absolute_injury_risk_reduction_sqerr[p] = mean(res$absolute_injury_risk_reduction_sqerr[index[p,]])
}
aver
aver = []
aver = NA
#colnamesforres = c("mean_impact_speed0_sqerr")
aver = as.data.frame(matrix(nrow=total_iter,ncol=0))
biggest = as.data.frame(matrix(nrow=total_iter,ncol=0))
smallest = as.data.frame(matrix(nrow=total_iter,ncol=0))
colnames(aver) = colnamesforres
index = matrix(nrow = total_iter,ncol = Sim_n)
for(p in 1:total_iter){
index[p,] = seq(p,total_iter*Sim_n,total_iter)
aver$iter[p] = mean(res$iter[p])
aver$mean_impact_speed0_sqerr[p] = mean(res$mean_impact_speed0_sqerr[index[p,]])
aver$absolute_impact_speed_reduction_sqerr[p] = mean(res$absolute_impact_speed_reduction_sqerr[index[p,]])
aver$proportion_crashes_avoided_sqerr[p] = mean(res$proportion_crashes_avoided_sqerr[index[p,]])
aver$absolute_injury_risk_reduction_sqerr[p] = mean(res$absolute_injury_risk_reduction_sqerr[index[p,]])
}
aver
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
total_iter
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/sim_data_to_R.R")
debugSource("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/run_post_analysis.R")
source("~/upload/Git/updated_Glance_Sampling/Glance_sampling/Rscript/sim_data_to_R.R")
=======
max
max <- labelled %>% group_by(caseID) %>% summarise(max = max(impact_speed1)) %>% pull
max
max <- labelled %>% group_by(caseID) %>% summarise(max = max(impact_speed0 - impact_speed0)) %>% pull
max
max <- labelled %>% group_by(caseID) %>% summarise(max = max(impact_speed0 - impact_speed1)) %>% pull
max
res <- active_learning(data, sampling_method = "optimised", target = "injury risk reduction, stratified", niter = 10)
source("~/GitHub/Glance_sampling/Rscript/active_learning.R")
res <- active_learning(data, sampling_method = "optimised", target = "injury risk reduction, stratified", niter = 10)
View(res$labelled)
View(res$res)
size <- with(unlabelled, injury_risk0_pred - injury_risk1_pred)
size[size <= 0] <- min(size[size > 0]) # Zeroes and negative values not allowed.
# Account for probability of (deceleration, glance) pair and probability of crash in baseline scenario.
size <- with(unlabelled, sqrt(collision_prob0_pred) * eoff_acc_prob * size)
# Probability proportional to size.
sampling_probability <- num_cases * size / sum(size)
plot(unlabelled$impact_speed0_pred, sampling_probability, bty = "l")
plot(unlabelled$impact_speed0_pred, sampling_probability, bty = "l", xlab = "Impact speed", ylab = "Sampling probability")
nStrata <- 10
sizeMat <- matrix(0, nrow = nrow(unlabelled), ncol = nStrata)
for ( i in 1:nStrata ) {
sizeMat[, i] <- with(unlabelled, ifelse(impact_speed0_pred > 10 * (i - 1) & impact_speed0_pred <= 10 * i, sqrt(collision_prob0_pred) * eoff_acc_prob * pmax(injury_risk0_pred - injury_risk1_pred, 0), rep(0, length(injury_risk0_pred))))
}
# Pooled 'size' is root sum of squares of standardised individual 'sizes'.
# Without standardisation: produces same result as non-stratified version.
size2 <- sizeMat^2
csum <- colSums(size2)
ix <- which(csum > 0)
size <- sqrt(rowSums(scale(size2[, ix], center = FALSE, scale = csum[ix])))
# To account for probability of (deceleration, glance) pair and probability of crash in baseline scenario.
# Note: use division here since we multiple both on row 98 and 118.
size <- with(unlabelled, (sqrt(collision_prob0_pred) * eoff_acc_prob)^(-1) * size)
size[is.na(size)] <- 0
size[size <= 0] <- min(size[size > 0]) # Zeroes and negative values not allowed.
# Account for probability of (deceleration, glance) pair and probability of crash in baseline scenario.
size <- with(unlabelled, sqrt(collision_prob0_pred) * eoff_acc_prob * size)
# Probability proportional to size.
sampling_probability <- num_cases * size / sum(size)
# Adjustment to account for sampling of multiple cases per iteration.
case_probability <- tapply(sampling_probability, unlabelled$caseID, sum)
points(unlabelled$impact_speed0_pred, sampling_probability, col = "firebrick")
points(unlabelled$impact_speed0_pred, sampling_probability, col = "red")
hist(sampling_probability)
hist(log(sampling_probability))
mean(log(sampling_probability))
mean(log(sampling_probability), na.rm = TRUE)
data
# num_cases_per_iteration should be integer between 1 and number of cases in input data set.
num_cases_per_iteration <- round(num_cases_per_iteration)
num_cases_per_iteration <- max(c(num_cases_per_iteration, 1))
num_cases_per_iteration <- min(c(num_cases_per_iteration, length(unique(data$caseID))))
# Load helper functions.
source("Rscript/calculate_sampling_scheme.R")
source("Rscript/estimate_targets.R")
source("Rscript/find_crashes.R")
source("Rscript/find_max_impact_crashes.R")
source("Rscript/find_non_crashes.R")
source("Rscript/initialise_grid.R")
source("Rscript/safe_cv_glmnet.R")
source("Rscript/safe_random_forest.R")
source("Rscript/update_predictions.R")
# To store results.
res <- NULL
# Calculate target quantities on full data.
ground_truth <- estimate_targets(data, weightvar = "eoff_acc_prob")
# Initialise on grid.
grid <- crossing(eoff = range(data$eoff), acc = range(data$acc)) %>% # Corner points.
add_row(eoff = quantile(data$eoff, 0.5, type = 1),
acc = quantile(data$acc, 0.5, type = 1)) %>% # Add centre point.
mutate(sim_count0 = 1,
sim_count1 = 1)
init <- initialise_grid(data, grid)
labelled <- init$labelled
unlabelled <- init$unlabelled
# Iterate
new_sample <- labelled
collision_counter <- 1
i <- 1
# If reduce_simulations_by_logic = TRUE:
if ( reduce_simulations_by_logic & nrow(new_sample) > 0 ) {
# Find all known non-crashes in unlabelled dataset.
ix <- find_non_crashes(new_sample, unlabelled)
unlabelled %<>%
mutate(non_crash0 = ifelse(row_number() %in% ix$non_crashes0, 1, non_crash0),
non_crash1 = ifelse(row_number() %in% ix$non_crashes1, 1, non_crash1),
sim_count0 = ifelse(row_number() %in% ix$non_crashes0, 0, sim_count0),
sim_count1 = ifelse(row_number() %in% ix$non_crashes1, 0, sim_count1))
# Find all known crashes in unlabelled dataset.
ix <- find_crashes(new_sample, unlabelled)
unlabelled %<>%
mutate(crash0 = ifelse(row_number() %in% ix$crashes0, 1, crash0),
crash1 = ifelse(row_number() %in% ix$crashes0, 1, crash1))
# Find all known maximal impact speed crashes in unlabelled dataset.
ix <- find_max_impact_crashes(new_sample, labelled, unlabelled)
unlabelled %<>%
mutate(max_impact0 = ifelse(row_number() %in% ix$max_impact_crashes0, 1, max_impact0),
max_impact1 = ifelse(row_number() %in% ix$max_impact_crashes1, 1, max_impact1),
sim_count0 = ifelse(row_number() %in% ix$max_impact_crashes0, 0, sim_count0),
sim_count1 = ifelse(row_number() %in% ix$max_impact_crashes1, 0, sim_count1))
} # End reduce_simulations_by_logic.
# Update predictions for cases with new data.
for ( j in unique(new_sample$caseID) ) {
# Baseline scenario.
pred0 <- update_predictions(labelled %>% filter(caseID == j),
unlabelled %>% filter(caseID == j),
yvar = "impact_speed0")
# With counter measure.
pred1 <- update_predictions(labelled %>% filter(caseID == j),
unlabelled %>% filter(caseID == j),
yvar = "impact_speed1")
# Add to unlabelled data set.
unlabelled_j <- unlabelled %>%
filter(caseID == j) %>%
mutate(collision_prob0_pred = pred0$collision_prob,
collision_prob1_pred = pred1$collision_prob,
impact_speed0_pred = pred0$impact_speed_pred,
impact_speed1_pred = pred1$impact_speed_pred,
injury_risk0_pred = (1 + exp(-(-5.35 + 0.11 * impact_speed0_pred / 2)))^(-1),
injury_risk1_pred = (1 + exp(-(-5.35 + 0.11 * impact_speed1_pred / 2)))^(-1),
injury_risk0_pred = ifelse(impact_speed0_pred > 0, injury_risk0_pred, 0), # Set injury risk to zero if no collision.
injury_risk1_pred = ifelse(impact_speed1_pred > 0, injury_risk1_pred, 0))
ix <- which(unlabelled$caseID == j)
unlabelled[ix, ] <- unlabelled_j
} # End update predictions.
# Calculate sampling probabilities.
prob <- calculate_sampling_scheme(unlabelled, labelled, sampling_method, target, num_cases_per_iteration)
sampling_method <- "injury risk reduction, stratified"
# Calculate sampling probabilities.
prob <- calculate_sampling_scheme(unlabelled, labelled, sampling_method, target, num_cases_per_iteration)
target <- "injury risk reduction, stratified"
sampling_method <- "optimised"
# Calculate sampling probabilities.
prob <- calculate_sampling_scheme(unlabelled, labelled, sampling_method, target, num_cases_per_iteration)
# Sample cases.
cases <- as.numeric(names(table(unlabelled$caseID)))
new_cases <- cases[which(UPmaxentropy(prob$case_probability) == 1)]
new_cases
cases
# Sample variations.
ix <- rep(0, nrow(unlabelled)) # Binary selection indicator.
for ( j in seq_along(new_cases) ) {
jx <- which(unlabelled$caseID == new_cases[j])
ix[jx] <- as.numeric(rmultinom(n = 1, size = 1, prob = prob$sampling_probability[jx]))
}
new_wt <- ix / prob$sampling_probability
new_wt[is.na(new_wt)] <- 0
# Get data for sampled observations.
new_sample <- unlabelled %>%
mutate(sampling_weight = 0,
new_wt = new_wt) %>%
filter(new_wt > 0) %>%
dplyr::select(caseID, eoff, acc, eoff_acc_prob, sim_count0, sim_count1, sampling_weight, new_wt) %>%
left_join(data, by = c("caseID", "eoff", "acc", "eoff_acc_prob"))
new_sample
View(new_sample)
table(new_wt)
labelled %>%
mutate(new_wt = 1) %>% # Re-query labelled data points with probability 1.
add_row(new_sample) %>%
mutate(sampling_weight = sampling_weight + (new_wt - sampling_weight) / collision_counter,
final_weight = eoff_acc_prob * sampling_weight) %>%
dplyr::select(-new_wt)
labelled %>%
mutate(new_wt = 1) %>% # Re-query labelled data points with probability 1.
add_row(new_sample) %>%
mutate(sampling_weight = sampling_weight + (new_wt - sampling_weight) / collision_counter,
final_weight = eoff_acc_prob * sampling_weight) %>%
dplyr::select(-new_wt) %>% View()
unlabelled %<>%
mutate(new_wt = new_wt) %>%
filter(new_wt <= 0) %>%
dplyr::select(-new_wt)
# Estimate target quantities.
crashes <- labelled %>% filter(impact_speed0 > 0)
effective_number_simulations0 <- effective_number_simulations1 <- nrow(labelled)
actual_number_simulations0 <- sum(labelled$sim_count0)
actual_number_simulations1 <- sum(labelled$sim_count1)
boot <- boot(crashes, statistic = function(data, ix) estimate_targets(data[ix, ], weightvar = "final_weight"), R = nboot)
est <- boot$t0 # Estimates.
se <- apply(boot$t, 2 , sd) # Standard error of estimates.
sqerr <- (est - ground_truth)^2 # Squared error with respect to ground truth.
nboot <- 100
# Estimate target quantities.
crashes <- labelled %>% filter(impact_speed0 > 0)
effective_number_simulations0 <- effective_number_simulations1 <- nrow(labelled)
actual_number_simulations0 <- sum(labelled$sim_count0)
actual_number_simulations1 <- sum(labelled$sim_count1)
boot <- boot(crashes, statistic = function(data, ix) estimate_targets(data[ix, ], weightvar = "final_weight"), R = nboot)
est <- boot$t0 # Estimates.
se <- apply(boot$t, 2 , sd) # Standard error of estimates.
sqerr <- (est - ground_truth)^2 # Squared error with respect to ground truth.
names(se) <- paste0(names(est), "_se")
names(sqerr) <- paste0(names(est), "_sqerr")
newres <- tibble(samping_method = sampling_method,
target = target,
reduce_simulations_by_logic = reduce_simulations_by_logic,
num_cases_per_iteration = num_cases_per_iteration) %>% # Meta-information.
add_column(iter = i,
neff0 = effective_number_simulations0,
neff1 = effective_number_simulations1,
neff_tot = effective_number_simulations0 + effective_number_simulations1,
nsim0 = actual_number_simulations0,
nsim1 = actual_number_simulations1,
nsim_tot = actual_number_simulations0 + actual_number_simulations1) %>% # Iteration history.
add_column(as_tibble(as.list(est))) %>% # Estimates.
add_column(as_tibble(as.list(se)))  %>% # Standard errors.
add_column(as_tibble(as.list(sqerr))) # Squared errors.
if ( is.null(res) ) {
res <- newres
} else {
res %<>%
add_row(newres)
}
# Increase counter if at least one new crash has been generated in baseline scenario.
collision_counter <- collision_counter + (any(new_sample$impact_speed0 > 0))
collision_counter
# If reduce_simulations_by_logic = TRUE:
if ( reduce_simulations_by_logic & nrow(new_sample) > 0 ) {
# Find all known non-crashes in unlabelled dataset.
ix <- find_non_crashes(new_sample, unlabelled)
unlabelled %<>%
mutate(non_crash0 = ifelse(row_number() %in% ix$non_crashes0, 1, non_crash0),
non_crash1 = ifelse(row_number() %in% ix$non_crashes1, 1, non_crash1),
sim_count0 = ifelse(row_number() %in% ix$non_crashes0, 0, sim_count0),
sim_count1 = ifelse(row_number() %in% ix$non_crashes1, 0, sim_count1))
# Find all known crashes in unlabelled dataset.
ix <- find_crashes(new_sample, unlabelled)
unlabelled %<>%
mutate(crash0 = ifelse(row_number() %in% ix$crashes0, 1, crash0),
crash1 = ifelse(row_number() %in% ix$crashes0, 1, crash1))
# Find all known maximal impact speed crashes in unlabelled dataset.
ix <- find_max_impact_crashes(new_sample, labelled, unlabelled)
unlabelled %<>%
mutate(max_impact0 = ifelse(row_number() %in% ix$max_impact_crashes0, 1, max_impact0),
max_impact1 = ifelse(row_number() %in% ix$max_impact_crashes1, 1, max_impact1),
sim_count0 = ifelse(row_number() %in% ix$max_impact_crashes0, 0, sim_count0),
sim_count1 = ifelse(row_number() %in% ix$max_impact_crashes1, 0, sim_count1))
} # End reduce_simulations_by_logic.
# Update predictions for cases with new data.
for ( j in unique(new_sample$caseID) ) {
# Baseline scenario.
pred0 <- update_predictions(labelled %>% filter(caseID == j),
unlabelled %>% filter(caseID == j),
yvar = "impact_speed0")
# With counter measure.
pred1 <- update_predictions(labelled %>% filter(caseID == j),
unlabelled %>% filter(caseID == j),
yvar = "impact_speed1")
# Add to unlabelled data set.
unlabelled_j <- unlabelled %>%
filter(caseID == j) %>%
mutate(collision_prob0_pred = pred0$collision_prob,
collision_prob1_pred = pred1$collision_prob,
impact_speed0_pred = pred0$impact_speed_pred,
impact_speed1_pred = pred1$impact_speed_pred,
injury_risk0_pred = (1 + exp(-(-5.35 + 0.11 * impact_speed0_pred / 2)))^(-1),
injury_risk1_pred = (1 + exp(-(-5.35 + 0.11 * impact_speed1_pred / 2)))^(-1),
injury_risk0_pred = ifelse(impact_speed0_pred > 0, injury_risk0_pred, 0), # Set injury risk to zero if no collision.
injury_risk1_pred = ifelse(impact_speed1_pred > 0, injury_risk1_pred, 0))
ix <- which(unlabelled$caseID == j)
unlabelled[ix, ] <- unlabelled_j
} # End update predictions.
# Calculate sampling probabilities.
prob <- calculate_sampling_scheme(unlabelled, labelled, sampling_method, target, num_cases_per_iteration)
# Sample cases.
cases <- as.numeric(names(table(unlabelled$caseID)))
new_cases <- cases[which(UPmaxentropy(prob$case_probability) == 1)]
# Sample variations.
ix <- rep(0, nrow(unlabelled)) # Binary selection indicator.
for ( j in seq_along(new_cases) ) {
jx <- which(unlabelled$caseID == new_cases[j])
ix[jx] <- as.numeric(rmultinom(n = 1, size = 1, prob = prob$sampling_probability[jx]))
}
new_wt <- ix / prob$sampling_probability
new_wt[is.na(new_wt)] <- 0
# Get data for sampled observations.
new_sample <- unlabelled %>%
mutate(sampling_weight = 0,
new_wt = new_wt) %>%
filter(new_wt > 0) %>%
dplyr::select(caseID, eoff, acc, eoff_acc_prob, sim_count0, sim_count1, sampling_weight, new_wt) %>%
left_join(data, by = c("caseID", "eoff", "acc", "eoff_acc_prob"))
new_sample
View(new_sample)
new_sample$impact_speed0 <- 0
View(new_sample)
labelled %>%
mutate(new_wt = 1) %>% # Re-query labelled data points with probability 1.
add_row(new_sample) %>%
mutate(sampling_weight = sampling_weight + (new_wt - sampling_weight) / collision_counter,
final_weight = eoff_acc_prob * sampling_weight) %>%
dplyr::select(-new_wt) %>% View()
View(labelled)
View(labelled)
# Update labelled and unlabelled sets.
labelled <- labelled %>%
mutate(new_wt = 1) %>% # Re-query labelled data points with probability 1.
add_row(new_sample) %>%
mutate(sampling_weight = sampling_weight + (new_wt - sampling_weight) / collision_counter,
final_weight = eoff_acc_prob * sampling_weight) %>%
dplyr::select(-new_wt)
View(labelled)
table(new_wt)
collision_counter <- 1
View(labelled)
labelled %<>% filter(sampling_weight <= 1)
# Update labelled and unlabelled sets.
labelled <- labelled %>%
mutate(new_wt = 1) %>% # Re-query labelled data points with probability 1.
add_row(new_sample) %>%
mutate(sampling_weight = sampling_weight + (new_wt - sampling_weight) / collision_counter,
final_weight = eoff_acc_prob * sampling_weight) %>%
dplyr::select(-new_wt)
unlabelled %<>%
mutate(new_wt = new_wt) %>%
filter(new_wt <= 0) %>%
dplyr::select(-new_wt)
# Estimate target quantities.
crashes <- labelled %>% filter(impact_speed0 > 0)
effective_number_simulations0 <- effective_number_simulations1 <- nrow(labelled)
actual_number_simulations0 <- sum(labelled$sim_count0)
actual_number_simulations1 <- sum(labelled$sim_count1)
boot <- boot(crashes, statistic = function(data, ix) estimate_targets(data[ix, ], weightvar = "final_weight"), R = nboot)
est <- boot$t0 # Estimates.
se <- apply(boot$t, 2 , sd) # Standard error of estimates.
sqerr <- (est - ground_truth)^2 # Squared error with respect to ground truth.
names(se) <- paste0(names(est), "_se")
names(sqerr) <- paste0(names(est), "_sqerr")
newres <- tibble(samping_method = sampling_method,
target = target,
reduce_simulations_by_logic = reduce_simulations_by_logic,
num_cases_per_iteration = num_cases_per_iteration) %>% # Meta-information.
add_column(iter = i,
neff0 = effective_number_simulations0,
neff1 = effective_number_simulations1,
neff_tot = effective_number_simulations0 + effective_number_simulations1,
nsim0 = actual_number_simulations0,
nsim1 = actual_number_simulations1,
nsim_tot = actual_number_simulations0 + actual_number_simulations1) %>% # Iteration history.
add_column(as_tibble(as.list(est))) %>% # Estimates.
add_column(as_tibble(as.list(se)))  %>% # Standard errors.
add_column(as_tibble(as.list(sqerr))) # Squared errors.
if ( is.null(res) ) {
res <- newres
} else {
res %<>%
add_row(newres)
}
# Increase counter if at least one new crash has been generated in baseline scenario.
collision_counter <- collision_counter + (any(new_sample$impact_speed0 > 0))
collision_counter
View(labelled)
# If reduce_simulations_by_logic = TRUE:
if ( reduce_simulations_by_logic & nrow(new_sample) > 0 ) {
# Find all known non-crashes in unlabelled dataset.
ix <- find_non_crashes(new_sample, unlabelled)
unlabelled %<>%
mutate(non_crash0 = ifelse(row_number() %in% ix$non_crashes0, 1, non_crash0),
non_crash1 = ifelse(row_number() %in% ix$non_crashes1, 1, non_crash1),
sim_count0 = ifelse(row_number() %in% ix$non_crashes0, 0, sim_count0),
sim_count1 = ifelse(row_number() %in% ix$non_crashes1, 0, sim_count1))
# Find all known crashes in unlabelled dataset.
ix <- find_crashes(new_sample, unlabelled)
unlabelled %<>%
mutate(crash0 = ifelse(row_number() %in% ix$crashes0, 1, crash0),
crash1 = ifelse(row_number() %in% ix$crashes0, 1, crash1))
# Find all known maximal impact speed crashes in unlabelled dataset.
ix <- find_max_impact_crashes(new_sample, labelled, unlabelled)
unlabelled %<>%
mutate(max_impact0 = ifelse(row_number() %in% ix$max_impact_crashes0, 1, max_impact0),
max_impact1 = ifelse(row_number() %in% ix$max_impact_crashes1, 1, max_impact1),
sim_count0 = ifelse(row_number() %in% ix$max_impact_crashes0, 0, sim_count0),
sim_count1 = ifelse(row_number() %in% ix$max_impact_crashes1, 0, sim_count1))
} # End reduce_simulations_by_logic.
# Update predictions for cases with new data.
for ( j in unique(new_sample$caseID) ) {
# Baseline scenario.
pred0 <- update_predictions(labelled %>% filter(caseID == j),
unlabelled %>% filter(caseID == j),
yvar = "impact_speed0")
# With counter measure.
pred1 <- update_predictions(labelled %>% filter(caseID == j),
unlabelled %>% filter(caseID == j),
yvar = "impact_speed1")
# Add to unlabelled data set.
unlabelled_j <- unlabelled %>%
filter(caseID == j) %>%
mutate(collision_prob0_pred = pred0$collision_prob,
collision_prob1_pred = pred1$collision_prob,
impact_speed0_pred = pred0$impact_speed_pred,
impact_speed1_pred = pred1$impact_speed_pred,
injury_risk0_pred = (1 + exp(-(-5.35 + 0.11 * impact_speed0_pred / 2)))^(-1),
injury_risk1_pred = (1 + exp(-(-5.35 + 0.11 * impact_speed1_pred / 2)))^(-1),
injury_risk0_pred = ifelse(impact_speed0_pred > 0, injury_risk0_pred, 0), # Set injury risk to zero if no collision.
injury_risk1_pred = ifelse(impact_speed1_pred > 0, injury_risk1_pred, 0))
ix <- which(unlabelled$caseID == j)
unlabelled[ix, ] <- unlabelled_j
} # End update predictions.
# Calculate sampling probabilities.
prob <- calculate_sampling_scheme(unlabelled, labelled, sampling_method, target, num_cases_per_iteration)
# Sample cases.
cases <- as.numeric(names(table(unlabelled$caseID)))
new_cases <- cases[which(UPmaxentropy(prob$case_probability) == 1)]
# Sample variations.
ix <- rep(0, nrow(unlabelled)) # Binary selection indicator.
for ( j in seq_along(new_cases) ) {
jx <- which(unlabelled$caseID == new_cases[j])
ix[jx] <- as.numeric(rmultinom(n = 1, size = 1, prob = prob$sampling_probability[jx]))
}
new_wt <- ix / prob$sampling_probability
new_wt[is.na(new_wt)] <- 0
# Get data for sampled observations.
new_sample <- unlabelled %>%
mutate(sampling_weight = 0,
new_wt = new_wt) %>%
filter(new_wt > 0) %>%
dplyr::select(caseID, eoff, acc, eoff_acc_prob, sim_count0, sim_count1, sampling_weight, new_wt) %>%
left_join(data, by = c("caseID", "eoff", "acc", "eoff_acc_prob"))
new_sample
View(labelled)
View(new_sample)
new_sample$impact_speed0 <- 0
new_sample
collision_counter
collision_counter <- 2
labelled2 <- labelled %>%
mutate(new_wt = 1) %>% # Re-query labelled data points with probability 1.
add_row(new_sample) %>%
mutate(sampling_weight = sampling_weight + (new_wt - sampling_weight) / collision_counter,
final_weight = eoff_acc_prob * sampling_weight) %>%
dplyr::select(-new_wt)
View(labelled)
labelled2 <- labelled %>%
mutate(new_wt = 1) %>% # Re-query labelled data points with probability 1.
add_row(new_sample) %>%
mutate(sampling_weight = sampling_weight + (new_wt - sampling_weight) / collision_counter,
final_weight = eoff_acc_prob * sampling_weight) %>%
dplyr::select(-new_wt)
View(labelled2)
(any(new_sample$impact_speed0 > 0)
any(new_sample$impact_speed0 > 0)
labelled2 <- labelled %>%
mutate(new_wt = 1) %>% # Re-query labelled data points with probability 1.
add_row(new_sample) %>%
mutate(sampling_weight = sampling_weight + any(new_sample$impact_speed0 > 0) * (new_wt - sampling_weight) / collision_counter,
final_weight = eoff_acc_prob * sampling_weight) %>%
dplyr::select(-new_wt)
View(labelled2)
collision_counter + any(new_sample$impact_speed0 > 0)
new_sample$impact_speed0
labelled2 <- labelled %>%
mutate(new_wt = 1) %>% # Re-query labelled data points with probability 1.
add_row(new_sample) %>%
mutate(sampling_weight = sampling_weight + any(new_sample$impact_speed0 > 0) *
(new_wt - sampling_weight) / collision_counter, # Update sampling weights if crash was generated.
final_weight = eoff_acc_prob * sampling_weight) %>%
dplyr::select(-new_wt)
View(labelled)
View(labelled %>% filter(sampling_weight > 1))
# Update labelled and unlabelled sets.
labelled <- labelled %>%
mutate(new_wt = 1) %>% # Re-query labelled data points with probability 1.
add_row(new_sample) %>%
mutate(sampling_weight = sampling_weight + any(new_sample$impact_speed0 > 0) *
(new_wt - sampling_weight) / collision_counter, # Update sampling weights if crash was generated. Non-crashes get zero weight.
final_weight = eoff_acc_prob * sampling_weight) %>%
dplyr::select(-new_wt)
View(labelled %>% filter(sampling_weight > 1))
new_sample$impact_speed0 <- 10
# Update labelled and unlabelled sets.
labelled <- labelled %>%
mutate(new_wt = 1) %>% # Re-query labelled data points with probability 1.
add_row(new_sample) %>%
mutate(sampling_weight = sampling_weight + any(new_sample$impact_speed0 > 0) *
(new_wt - sampling_weight) / collision_counter, # Update sampling weights if crash was generated. Non-crashes get zero weight.
final_weight = eoff_acc_prob * sampling_weight) %>%
dplyr::select(-new_wt)
View(labelled %>% filter(sampling_weight > 1))
new_sample$impact_speed0 <- 0''
new_sample$impact_speed0 <- 0
# Update labelled and unlabelled sets.
labelled <- labelled %>%
mutate(new_wt = 1) %>% # Re-query labelled data points with probability 1.
add_row(new_sample) %>%
mutate(sampling_weight = sampling_weight + any(new_sample$impact_speed0 > 0) *
(new_wt - sampling_weight) / collision_counter, # Update sampling weights if crash was generated. Non-crashes get zero weight.
final_weight = eoff_acc_prob * sampling_weight) %>%
dplyr::select(-new_wt)
View(labelled %>% filter(sampling_weight > 1))
new_sample$impact_speed0 <- 20
# Update labelled and unlabelled sets.
labelled <- labelled %>%
mutate(new_wt = 1) %>% # Re-query labelled data points with probability 1.
add_row(new_sample) %>%
mutate(sampling_weight = sampling_weight + any(new_sample$impact_speed0 > 0) *
(new_wt - sampling_weight) / collision_counter, # Update sampling weights if crash was generated. Non-crashes get zero weight.
final_weight = eoff_acc_prob * sampling_weight) %>%
dplyr::select(-new_wt)
View(labelled %>% filter(sampling_weight > 1))
active_learning(data, niter = 10)
res <- active_learning(data, niter = 10)
View(res$labelled)
source("~/GitHub/Glance_sampling/Rscript/active_learning.R")
res <- active_learning(data, niter = 10)
View(res$labelled)
res <- active_learning(data, niter = 20)
View(res$labelled)
135.3888889 - 135.2777778
135.2777778 - 0.11111111
View(res$crashes)
>>>>>>> Stashed changes
